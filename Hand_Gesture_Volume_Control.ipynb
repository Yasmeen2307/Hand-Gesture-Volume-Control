{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvorDqYg7NBp/+2ZhrVbeu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yasmeen2307/Hand-Gesture-Volume-Control/blob/main/Hand_Gesture_Volume_Control.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project On Hand Gesture Volume Control"
      ],
      "metadata": {
        "id": "y9NWzflVB5n5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T1JidyHBGt4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "import numpy as np\n",
        "from ctypes import cast, POINTER\n",
        "from comtypes import CLSCTX_ALL\n",
        "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
        "\n",
        "# solution APIs\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "# Volume Control Library Usage\n",
        "devices = AudioUtilities.GetSpeakers()\n",
        "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
        "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
        "volRange = volume.GetVolumeRange()\n",
        "minVol , maxVol , volBar, volPer= volRange[0] , volRange[1], 400, 0\n",
        "\n",
        "# Webcam Setup\n",
        "wCam, hCam = 640, 480\n",
        "cam = cv2.VideoCapture(0)\n",
        "cam.set(3,wCam)\n",
        "cam.set(4,hCam)\n",
        "\n",
        "# Mediapipe Hand Landmark Model\n",
        "with mp_hands.Hands(\n",
        "    model_complexity=0,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5) as hands:\n",
        "\n",
        "  while cam.isOpened():\n",
        "    success, image = cam.read()\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    if results.multi_hand_landmarks:\n",
        "      for hand_landmarks in results.multi_hand_landmarks:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            image,\n",
        "            hand_landmarks,\n",
        "            mp_hands.HAND_CONNECTIONS,\n",
        "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "            mp_drawing_styles.get_default_hand_connections_style()\n",
        "            )\n",
        "\n",
        "    # multi_hand_landmarks method for Finding postion of Hand landmarks\n",
        "    lmList = []\n",
        "    if results.multi_hand_landmarks:\n",
        "      myHand = results.multi_hand_landmarks[0]\n",
        "      for id, lm in enumerate(myHand.landmark):\n",
        "        h, w, c = image.shape\n",
        "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "        lmList.append([id, cx, cy])\n",
        "\n",
        "    # Assigning variables for Thumb and Index finger position\n",
        "    if len(lmList) != 0:\n",
        "      x1, y1 = lmList[4][1], lmList[4][2]\n",
        "      x2, y2 = lmList[8][1], lmList[8][2]\n",
        "\n",
        "      # Marking Thumb and Index finger\n",
        "      cv2.circle(image, (x1,y1),15,(255,255,255))\n",
        "      cv2.circle(image, (x2,y2),15,(255,255,255))\n",
        "      cv2.line(image,(x1,y1),(x2,y2),(0,255,0),3)\n",
        "      length = math.hypot(x2-x1,y2-y1)\n",
        "      if length < 50:\n",
        "        cv2.line(image,(x1,y1),(x2,y2),(0,0,255),3)\n",
        "\n",
        "      vol = np.interp(length, [50, 220], [minVol, maxVol])\n",
        "      volume.SetMasterVolumeLevel(vol, None)\n",
        "      volBar = np.interp(length, [50, 220], [400, 150])\n",
        "      volPer = np.interp(length, [50, 220], [0, 100])\n",
        "\n",
        "      # Volume Bar\n",
        "      cv2.rectangle(image, (50, 150), (85, 400), (0, 0, 0), 3)\n",
        "      cv2.rectangle(image, (50, int(volBar)), (85, 400), (0, 0, 0), cv2.FILLED)\n",
        "      cv2.putText(image, f'{int(volPer)} %', (40, 450), cv2.FONT_HERSHEY_COMPLEX,\n",
        "                1, (0, 0, 0), 3)\n",
        "\n",
        "    cv2.imshow('handDetector', image)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "      break\n",
        "cam.release()"
      ]
    }
  ]
}